---
permalink: /
title: "Biography"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

<style>
.page__content p {
  text-align: justify !important;
  text-justify: inter-word;
  line-height: 1.5;
}
</style>

I am currently a Postdoc Researcher at Princeton University, fortunately working with Prof. [Mengdi Wang](https://mwang.princeton.edu/). Prior to this, I served as a Senior Research Assistant at Princeton University from January to July 2025. I received my Ph.D. degree from Peking University in July 2025, jointly supervised by Prof. [Bin Cui](https://cuibinpku.github.io/) and Prof. [Luxia Zhang](https://www.nihds.pku.edu.cn/en/info/1027/1002.htm). During my doctoral studies, I was selected for the [ByteDance Top Seed Talent Program](https://seed.bytedance.com/en/topseed?view_from=homepage_tab). I was also fortunate to collaborate with [Yang Song](https://yang-song.net/), [Shuicheng Yan](https://scholar.google.com.hk/citations?user=DNuiPHwAAAAJ&hl=zh-CN), [Ming-Hsuan Yang](https://scholar.google.com/citations?user=p9-ohHsAAAAJ&hl=zh-CN), [Bernard Ghanem](https://scholar.google.com/citations?user=rVsGTeEAAAAJ&hl=zh-CN), [Stefano Ermon](https://scholar.google.com/citations?user=ogXTOZ4AAAAJ&hl=en), and [Jure Leskovec](https://scholar.google.com/citations?user=Q_kKkIUAAAAJ&hl=zh-CN). I am opening to academic and industrial research opportunities. Please feel free to reach out for potential collaborations or discussions.   

We have opening positions for PhDs, Masters and Research Interns (Princeton University and Peking University, available in-person and remote). Also, I am in charge of [a reasearch team](https://github.com/Gen-Verse) and have led a series of works on Diffusion Models and LLMs, including [RPG-DiffusionMaster](https://openreview.net/forum?id=DgLFkAPwuZ)![GitHub stars](https://img.shields.io/github/stars/YangLing0818/RPG-DiffusionMaster), [MMaDA](https://arxiv.org/abs/2505.15809)![GitHub stars](https://img.shields.io/github/stars/Gen-Verse/MMaDA), [Diffusion-Survey](https://arxiv.org/abs/2209.00796)![GitHub stars](https://img.shields.io/github/stars/YangLing0818/Diffusion-Models-Papers-Survey-Taxonomy), [Buffer of Thoughts](https://arxiv.org/pdf/2406.04271)![GitHub stars](https://img.shields.io/github/stars/YangLing0818/buffer-of-thought-llm), [ReasonFlux/PRM/Coder](https://github.com/Gen-Verse/ReasonFlux)![GitHub stars](https://img.shields.io/github/stars/Gen-Verse/ReasonFlux), [dLLM-RL](https://github.com/Gen-Verse/dLLM-RL)![GitHub stars](https://img.shields.io/github/stars/Gen-Verse/dLLM-RL), [VideoTetris](https://arxiv.org/abs/2406.04277)![GitHub stars](https://img.shields.io/github/stars/YangLing0818/VideoTetris), [Consistency Flow Matching](https://arxiv.org/abs/2407.02398)![GitHub stars](https://img.shields.io/github/stars/YangLing0818/consistency_flow_matching), [IterComp](https://arxiv.org/abs/2410.07171)![GitHub stars](https://img.shields.io/github/stars/YangLing0818/IterComp), [Rectified Diffusion](https://openreview.net/forum?id=nEDToD1R8M)![GitHub stars](https://img.shields.io/github/stars/G-U-N/Rectified-Diffusion). 

My research has been sponsored by leading companies including ByteDance, Ant Group, and Xiaomi. I welcome opportunities for collaboration and partnership discussions with additional enterprises and organizations.  
[Email](mailto:yangling0818@163.com) | [WeChat](./image-1.png) | [Github](https://github.com/YangLing0818) | [Group Github](https://github.com/Gen-Verse) | [Google Scholar](https://scholar.google.com.hk/citations?user=sIKujqAAAAAJ&hl=en) | [Twitter](https://x.com/LingYang_PU) | [HuggingFace](https://huggingface.co/Gen-Verse) | [小红书](https://www.xiaohongshu.com/user/profile/5bf9033627150f0001533e35) 



# Research Summary
My goal is to build powerful generative models capable of **understanding, generating and reasoning** with high-dimensional data across diverse modalities. I currently focus on developing advanced generative models, including their *training methodologies, architecture design, alignment, inference efficiency and applications*.
<!--
<img width="856" height="357" alt="image" src="https://github.com/user-attachments/assets/b15cc2b3-c6a8-41a7-a943-30b3171ac5a4" />
-->


<img width="850" height="1074" alt="image" src="https://github.com/user-attachments/assets/e0626275-9b3c-47da-b3f2-8b3607d03de2" />


**Generative Model Foundations**  
  * Diffusion Model Foundations: [RPG](https://openreview.net/forum?id=DgLFkAPwuZ), [MMaDA](https://github.com/Gen-Verse/MMaDA), [ContextDiff](https://openreview.net/forum?id=nFMS6wF2xq), [dLLM-RL](https://arxiv.org/abs/2509.06949), [Consistency Flow Matching](https://arxiv.org/abs/2407.02398), [Diffusion-Sharpening](https://arxiv.org/abs/2502.12146), [Rectified Diffusion](https://openreview.net/forum?id=nEDToD1R8M), [ConPreDiff](https://proceedings.neurips.cc/paper_files/paper/2023/hash/7664a7e946a84ac5e97649a967717cf2-Abstract-Conference.html), [SADM](https://openaccess.thecvf.com/content/CVPR2024/html/Yang_Structure-Guided_Adversarial_Training_of_Diffusion_Models_CVPR_2024_paper.html)
  * Language Model Innovations: [Buffer of Thought](https://arxiv.org/pdf/2406.04271), [MMaDA](https://github.com/Gen-Verse/MMaDA), [ReasonFlux](https://github.com/Gen-Verse/ReasonFlux), [ReasonFlux-Coder](https://github.com/Gen-Verse/CURE), [ReasonFlux-PRM](https://github.com/Gen-Verse/ReasonFlux), [TraDo](https://arxiv.org/abs/2509.06949), [SuperCorrect](https://arxiv.org/abs/2410.09008)
  * Large-Scale Reinforcement Learning: [dLLM-RL](https://github.com/Gen-Verse/dLLM-RL), [MMaDA](https://github.com/Gen-Verse/MMaDA), [ReasonFlux-Coder](https://github.com/Gen-Verse/CURE), [ReasonFlux-PRM](https://github.com/Gen-Verse/ReasonFlux), [HermesFlow](https://arxiv.org/abs/2502.12148)
  * Intelligent Agent Systems: [Alita](https://arxiv.org/abs/2505.20286), [AgentDistill](https://arxiv.org/abs/2506.14728), [ScoreFlow](https://github.com/Gen-Verse/ScoreFlow), [Multi-Actor Collaboration](https://arxiv.org/abs/2410.08102), [Preacher](https://arxiv.org/abs/2508.09632), [EmoAgent](https://arxiv.org/abs/2504.09689)
    
  
**Generative Applications**
  * Multimodal Content Generation (spanning image, 3D, and 4D synthesis): [IterComp](https://openreview.net/forum?id=4w99NAikOE), [VideoTetris](https://arxiv.org/abs/2406.04277), [ScoreLiDAR](https://github.com/happyw1nd/ScoreLiDAR), [IPDreamer](https://openreview.net/forum?id=3PguviI7Uf), [EditWorld](https://arxiv.org/abs/2405.14785), [Trans4D](https://arxiv.org/abs/2410.07155), [WideRange4D](https://arxiv.org/abs/2503.13435) 
  * AI for Scientific Discovery: [IPDiff](https://openreview.net/forum?id=qH9nrMNTIW), [IRDiff](https://openreview.net/forum?id=eejhD9FCP3), [BindDM](https://ojs.aaai.org/index.php/AAAI/article/view/29162), [RL for Scientific Reasoning](https://arxiv.org/abs/2505.19501)  

**Book Publication**

**"Diffusion Model: Theory, Application, and Code Practice of Generative AI Models"**  
Published by Electronics Industry Press (电子工业出版社), 2023  
[Purchase Link](https://item.m.jd.com/product/14075554.html) | Selected as **Annual Outstanding Author**


# <font color=red> What's New </font>
* Invited to give a talk at [ICCV 2025 Workshop on Multi-Modal Reasoning for Agentic Intelligence](https://agent-intelligence.github.io/agent-intelligence/).
* **5 papers** about LLMs and Multimodal LLMs are accepted by **NeurIPS 2025**, including [MMaDA](https://github.com/Gen-Verse/MMaDA), [CURE & ReasonFlux-Coder](https://github.com/Gen-Verse/ReasonFlux) **(<font color=red>Spotlight Paper, Top 3%</font>)**, [ReasonFlux-PRM](https://github.com/Gen-Verse/ReasonFlux), [Transformer-Copilot](https://arxiv.org/abs/2505.16270) **(<font color=red>Spotlight Paper, Top 3%</font>)** and [HermesFlow](https://arxiv.org/abs/2502.12148). 
* **3 papers** about LLMs and Agents are accepted by **EMNLP 2025**, including [EmoAgent](https://arxiv.org/abs/2504.09689) **(<font color=red>Oral Paper, Top 1%</font>)** and [TreeBoN](https://arxiv.org/abs/2410.16033).
* **2 papers** about diffusion are accepted by **ACM MM 2025**, including [Inversion-DPO](https://arxiv.org/abs/2507.11554) and [EditWorld](https://arxiv.org/abs/2405.14785).
* I was selected as a finalist for the [2025 WAIC Yunfan Award](https://www.thegaiaa.org/en/awards_mrzx).
* I was invited to participate in a roundtable forum at WAIC 2025, hosted by Prof. [Dahua Lin](https://scholar.google.com/citations?user=GMzzRRUAAAAJ&hl=en).
* **2 papers** about agent and diffusion are accepted by **ICCV 2025**, including one [ScoreLiDAR](https://github.com/happyw1nd/ScoreLiDAR)**(Oral Paper)** **(<font color=red>Oral Paper, Top 1%</font>)** and [Paper2Video Agent](https://arxiv.org/abs/2508.09632).
* **1 paper** about LLMs is accepted by **ACL 2025**, including [Multi-Actor Collaboration](https://arxiv.org/abs/2410.08102).
* I was invited as an **Area Chair** at **NeurIPS 2025**.
* **6 papers** about LLMs and Diffusion Models are accepted by **ICLR 2025**, including [SuperCorrect](https://arxiv.org/abs/2410.09008), [Rectified Diffusion](https://openreview.net/forum?id=nEDToD1R8M), [IterComp](https://openreview.net/forum?id=4w99NAikOE) and [IPDreamer](https://openreview.net/forum?id=3PguviI7Uf).
* I was invited to give a talk at Princeton AI Lab, hosted by Prof. [Mengdi Wang](https://ece.princeton.edu/people/mengdi-wang).
* **5 papers** about Diffusion Models and LLMs are accepted by **NeurIPS 2024**, including [Buffer of Thoughts](https://github.com/YangLing0818/buffer-of-thought-llm) **(<font color=red>Spotlight Paper, Top 3%</font>)**.
* **2 papers** about Diffusion Models and AI for Science are accepted by **ICML 2024**.
* **1 paper** about general/molecular graph diffusion is accepted by **TKDE 2024**.
* **1 paper** about improved training algorithm of Diffusion Transformers (DiT), DDPMs and Score SDEs is accepted by **CVPR 2024**.
* **3 papers** about Diffusion Models, GNN, AI for Science are accepted by **ICLR 2024**.
* **1 paper** about molecular diffusion models is accepted by **AAAI 2024**.
* **1 paper** about diffusion model survey collaborating with OpenAI is accepted by **ACM Computing Surveys**.
* **1 paper** about diffusion models is accepted by **NeurIPS 2023**.
* I publish [a book about Diffusion Models](https://item.m.jd.com/product/14075554.html).
* **1 paper** is accepted by **TNNLS 2023**.
* **1 paper** is accepted by **TKDE 2023**.
* **2 papers** are accepted as **ICML 2022** **(<font color=red>Spotlight Paper, Top 3%</font>)**.
* **1 paper** is accepted by **CVPR 2020**.

<!-- * I release [ReasonFlux](https://github.com/Gen-Verse/ReasonFlux)![GitHub stars](https://img.shields.io/github/stars/Gen-Verse/ReasonFlux), **beating OpenAI o1-preview and DeepSeek-V3** with hierarchical reinforcement learning on 8GPUs. -->

# Selected Publications 

*\*Co-first author, <sup>+</sup>Corresponding author*

*For a complete list, see my [Google Scholar profile](https://scholar.google.com.hk/citations?user=sIKujqAAAAAJ&hl=en)*

### Recent Highlighted Work
* **Buffer of Thoughts: Thought-Augmented Reasoning with Large Language Models**  
**Ling Yang**<sup>+</sup>, Zhaochen Yu, Tianjun Zhang, Shiyi Cao, Minkai Xu, Wentao Zhang, Joseph E Gonzalez, Bin Cui  
NeurIPS 2024 **(<font color=red>Spotlight Top 3%</font>)**  [paper](https://arxiv.org/pdf/2406.04271) | [code](https://github.com/YangLing0818/buffer-of-thought-llm) | [tweet](https://x.com/omarsar0/status/1799113545696567416)

* **Mastering Text-to-Image Diffusion: Recaptioning, Planning, and Generating with Multimodal LLMs**  
**Ling Yang**<sup>+</sup>, Zhaochen Yu, Chenlin Meng, Minkai Xu, Stefano Ermon, Bin Cui  
ICML 2024  [paper](https://openreview.net/forum?id=DgLFkAPwuZ) | [code](https://github.com/YangLing0818/RPG-DiffusionMaster) | [tweet](https://x.com/_akhaliq/status/1749633221514461489)

* **MMaDA: Multimodal Large Diffusion Language Models**  
**Ling Yang**<sup>+</sup>, Ye Tian, Bowen Li, Xinchen Zhang, Ke Shen, Yunhai Tong, Mengdi Wang  
NeurIPS 2025 [paper](https://arxiv.org/abs/2505.15809) | [code](https://github.com/Gen-Verse/MMaDA) | [tweet](https://x.com/_akhaliq/status/1925384556279898139)

* **Revolutionizing Reinforcement Learning Framework for Diffusion Large Language Models**  
Yinjie Wang, **Ling Yang**\*<sup>+</sup>, Bowen Li, Ye Tian, Ke Shen, Mengdi Wang  
[paper](https://arxiv.org/abs/2509.06949) | [code](https://github.com/Gen-Verse/dLLM-RL) | [tweet](https://x.com/_akhaliq/status/1965422743194927429)

* **Distilling Diffusion Models to Efficient 3D LiDAR Scene Completion**  
Shengyuan Zhang, An Zhao, **Ling Yang**, Zejian Li, Chenye Meng, Haoran Xu, Tianrun Chen, AnYang Wei, Perry Pengyun GU, Lingyun Sun  
ICCV 2025 **(<font color=red>Oral Top 1%</font>)**  [paper](https://arxiv.org/abs/2412.03515) | [code](https://github.com/happyw1nd/ScoreLiDAR) 


* **ReasonFlux: Hierarchical LLM Reasoning via Scaling Thought Templates**  
**Ling Yang**<sup>+</sup>, Zhaochen Yu, Bin Cui, Mengdi Wang  
[paper](https://arxiv.org/abs/2502.06772) | [code](https://github.com/Gen-Verse/ReasonFlux) | [tweet](https://x.com/_akhaliq/status/1889187356651012599)

* **Co-Evolving LLM Coder and Unit Tester via Reinforcement Learning (ReasonFlux-Coder)**  
Yinjie Wang, **Ling Yang**\*<sup>+</sup>, Ye Tian, Ke Shen, Mengdi Wang  
NeurIPS 2025 **(<font color=red>Spotlight Top 3%</font>)**  [paper](https://arxiv.org/abs/2506.03136) | [code](https://github.com/Gen-Verse/CURE) | [tweet](https://x.com/_akhaliq/status/1930281721926234437)

* **ReasonFlux-PRM: Trajectory-Aware PRMs for Long Chain-of-Thought Reasoning in LLMs**  
Jiaru Zou, **Ling Yang**\*<sup>+</sup>, Jingwen Gu, Jiahao Qiu, Ke Shen, Jingrui He, Mengdi Wang  
NeurIPS 2025 [paper](https://arxiv.org/abs/2506.18896) | [code](https://github.com/Gen-Verse/ReasonFlux) | [tweet](https://x.com/_akhaliq/status/1937345023005048925)

* **SuperCorrect: Advancing Small LLM Reasoning with Thought Template Distillation and Self-Correction**.  
**Ling Yang**<sup>+</sup>, Zhaochen Yu, Tianjun Zhang, Minkai Xu, Joseph E. Gonzalez, Bin CUI, Shuicheng YAN  
ICLR 2025 [paper](https://openreview.net/forum?id=PyjZO7oSw2) | [code](https://github.com/YangLing0818/SuperCorrect-llm)


* **Transformer Copilot: Learning from The Mistake Log in LLM Fine-tuning**  
Jiaru Zou, Yikun Ban, Zihao Li, Yunzhe Qi, Ruizhong Qiu, **Ling Yang**<sup>+</sup>, Jingrui He  
NeurIPS 2025 **(<font color=red>Spotlight Top 3%</font>)**  [paper](https://arxiv.org/abs/2505.16270) | [code](https://github.com/jiaruzouu/TransformerCopilot)

### Core Contributions to Generative Foundations and Applications
* **HermesFlow: Seamlessly Closing the Gap in Multimodal Understanding and Generation**  
Ling Yang<sup>+</sup>, Xinchen Zhang, Ye Tian, Chenming Shang, Minghao Xu, Wentao Zhang, Bin Cui  
NeurIPS 2025 [paper](https://arxiv.org/abs/2502.12148) | [code](https://github.com/Gen-Verse/HermesFlow)

* **IterComp: Iterative Composition-Aware Feedback Learning from Model Gallery for Text-to-Image Generation**  
Xinchen Zhang\*, **Ling Yang**\*, Guohao Li, Yaqi Cai, Jiake Xie, Yong Tang, Yujiu Yang, Mengdi Wang, Bin Cui  
ICLR 2025 [paper](https://arxiv.org/abs/2410.07171) | [code](https://github.com/YangLing0818/IterComp) | [tweet](https://x.com/_akhaliq/status/1844272544687509910)

* **Rectified Diffusion: Straightness Is Not Your Need in Rectified Flow**  
Fu-Yun Wang, **Ling Yang**, Zhaoyang Huang, Mengdi Wang, Hongsheng Li  
ICLR 2025 [paper](https://openreview.net/forum?id=nEDToD1R8M) | [code](https://github.com/G-U-N/Rectified-Diffusion)

* **Consistency Flow Matching: Defining Straight Flows with Velocity Consistency**  
  **Ling Yang**<sup>+</sup>, Zixiang Zhang, Zhilong Zhang, Xingchao Liu, Minkai Xu, Wentao Zhang, Chenlin Meng, Stefano Ermon, Bin Cui  
  [paper](https://arxiv.org/abs/2407.02398) | [code](https://github.com/YangLing0818/consistency_flow_matching) | [tweet](https://x.com/LingYang_PKU/status/1808509588414800224)

* **Cross-Modal Contextualized Diffusion Models for Text-Guided Visual Generation and Editing**  
**Ling Yang**, Zhilong Zhang, Zhaochen Yu, Jingwei Liu, Minkai Xu, Stefano Ermon, Bin CUI  
ICLR 2024 [paper](https://openreview.net/forum?id=nFMS6wF2xq) | [code](https://github.com/YangLing0818/ContextDiff)

* **Structure-Guided Adversarial Training of Diffusion Models**  
**Ling Yang**, Haotian Qian, Zhilong Zhang, Jingwei Liu, Bin CUI  
CVPR 2024 [paper](https://openaccess.thecvf.com/content/CVPR2024/papers/Yang_Structure-Guided_Adversarial_Training_of_Diffusion_Models_CVPR_2024_paper.pdf)

* **Improving Diffusion-Based Image Synthesis with Context Prediction**  
**Ling Yang**, Jingwei Liu, Shenda Hong, Zhilong Zhang, Zhilin Huang, Zheming Cai, Wentao Zhang, Bin CUI  
NeurIPS 2024 [paper](https://proceedings.neurips.cc/paper_files/paper/2023/hash/7664a7e946a84ac5e97649a967717cf2-Abstract-Conference.html)

* **Diffusion Models: A Comprehensive Survey of Methods and Applications**  
**Ling Yang**, Zhilong Zhang, **Yang Song (OpenAI)**, Shenda Hong, Runsheng Xu, Yue Zhao, Wentao Zhang, Bin CUI, Ming-Hsuan Yang  
ACM Computing Surveys 2023 [paper](https://arxiv.org/abs/2209.00796) | [code](https://github.com/YangLing0818/Diffusion-Models-Papers-Survey-Taxonomy)


* **VideoTetris: Towards Compositional Text-to-Video Generation**  
Ye Tian\*, **Ling Yang**\*<sup>+</sup>, Haotian Yang, Yuan Gao, Yufan Deng, Jingmin Chen, Xintao Wang, Zhaochen Yu, Xin Tao, Pengfei Wan, Di Zhang, Bin Cui  
NeurIPS 2024  [paper](https://arxiv.org/abs/2406.04277) | [code](https://github.com/YangLing0818/VideoTetris) | [tweet](https://x.com/_akhaliq/status/1798897351534489608)



<!-- **[First Diffusion Survey with OpenAI]** [Diffusion Models: A Comprehensive Survey of Methods and Applications](https://arxiv.org/abs/2209.00796)

*Author List*: **Ling Yang**, Zhilong Zhang, Yang Song, Shenda Hong, Runsheng Xu, Yue Zhao, Yingxia Shao, Wentao Zhang, Bin Cui, Ming-Hsuan Yang



**[ICLR 2024]** [Protein-Ligand Interaction Prior for Binding-aware 3D Molecule Diffusion Models](https://openreview.net/forum?id=qH9nrMNTIW)

*Author List*: Zhilin Huang\*, **Ling Yang**\*, Xiangxin Zhou, Zhilong Zhang, Wentao Zhang, Xiawu Zheng, Jie Chen, Yu Wang, Bin Cui, Wenming Yang

**[ICML 2024]** [Interaction-based Retrieval-augmented Diffusion Models for Protein-specific 3D Molecule Generation](https://openreview.net/forum?id=eejhD9FCP3)

*Author List*: Zhilin Huang\*, **Ling Yang**\*, Xiangxin Zhou, Chujun Qin, Yijie Yu, Xiawu Zheng, Zikun Zhou, Wentao Zhang, Yu Wang, Wenming Yang -->

<!-- **[ICLR 2024]** [VQGraph: Rethinking Graph Representation Space for Bridging GNNs and MLPs](https://openreview.net/forum?id=h6Tz85BqRI)

*Author List*: **Ling Yang**, Ye Tian, Minkai Xu, Zhongyi Liu, Shenda Hong, Wei Qu, Wentao Zhang, Bin Cui, Muhan Zhang, Jure Leskovec -->

### Additional Selected Publications

* **VQGraph: Rethinking Graph Representation Space for Bridging GNNs and MLPs**  
**Ling Yang**, Ye Tian, Minkai Xu, Zhongyi Liu, Shenda Hong, Wei Qu, Wentao Zhang, Bin Cui, Muhan Zhang, Jure Leskovec  
ICLR 2024 [paper](https://openreview.net/forum?id=h6Tz85BqRI) | [code](https://github.com/YangLing0818/VQGraph)

* **Dpgn: Distribution propagation graph network for few-shot learning**  
**Ling Yang**, Liangliang Li, Zilun Zhang, Xinyu Zhou, Erjin Zhou, Yu Liu  
CVPR 2020  [paper](http://openaccess.thecvf.com/content_CVPR_2020/html/Yang_DPGN_Distribution_Propagation_Graph_Network_for_Few-Shot_Learning_CVPR_2020_paper.html) | [code](https://github.com/megvii-research/DPGN)

* **Unsupervised time-series representation learning with iterative bilinear temporal-spectral fusion**  
**Ling Yang**<sup>+</sup>, Shenda Hong  
ICML 2022 **(<font color=red>Spotlight Top 3%</font>)** [paper](https://proceedings.mlr.press/v162/yang22e.html)

* **EmoAgent: Assessing and Safeguarding Human-AI Interaction for Mental Health Safety**  
Jiahao Qiu, Yinghui He, Xinzhe Juan, Yimin Wang, Yuhan Liu, Zixin Yao, Yue Wu, Xun Jiang, Ling Yang, Mengdi Wang  
EMNLP 2025 **(<font color=red>Oral Top 1%</font>)** [paper](https://arxiv.org/abs/2504.09689) | [code](https://github.com/1akaman/EmoAgent)


<!--
# Mentoring History
[Zhaochen Yu](https://zhaochenyu0201.github.io/) (Incoming Ph.D. student at National University of Singapore)

[Xinchen Zhang](https://cominclip.github.io/) (Master student at Tsinghua University)

[Ye Tian](https://tyfeld.github.io/) (Ph.D. student at Peking University)

[Zhilin Huang](https://scholar.google.com/citations?user=qiff_5AAAAAJ&hl=zh-CN) (Ph.D. student at Tsinghua University)

[Zhilong Zhang](https://scholar.google.com/citations?user=irQZ_qgAAAAJ&hl=en) (Ph.D. student at Tsinghua University)

[Yinjie Wang](https://scholar.google.com/citations?user=GvufmnwAAAAJ&hl=en) (Ph.D. student at The University of Chicago)

[Jiaru Zou](https://scholar.google.com/citations?user=GzLTey4AAAAJ&hl=en) (Master student at University of Illinois Urbana-Champaign)

[Jiacheng Guo](https://scholar.google.com/citations?user=-gNBIsYAAAAJ&hl=en) (Ph.D. student at Princeton University)
-->

# Academic Services

* Area Chair:
  * NeurIPS 2025, ICLR 2026

* Program Committee or Reviewer:
  * ICML 2025, ICLR 2025, CVPR 2025, ICCV 2025, AAAI 2025
  * SIGGRAPH 2024, ICML 2024, ICLR 2024, NeurIPS 2024, CVPR 2024, AAAI 2024
  * ICML 2023, ICLR 2023, NeurIPS 2023, CVPR 2023, AAAI 2023
  * ICML 2022, ICLR 2022, NeurIPS 2022
 
* Journal Reviewer
  * ACM Computing Surveys (CSUR)
  * IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)
  * IEEE Transactions on Knowledge and Data Engineering (TKDE)
  * IEEE Transactions on Circuits and Systems for Video Technology (TCSVT)
  * IEEE Transactions on Neural Networks and Learning Systems (TNNLS)
  * Pattern Recognition (PR)

# Invited Talks
- Invited to give a talk at ICCV 2025 Workshop on [MMRAgI](https://agent-intelligence.github.io/agent-intelligence/), 2025.
- Invited to give a talk at [Institute of Automation of the Chinese Academy of Sciences](http://english.ia.cas.cn/), 2025.
- Invited to give a talk at a roundtable forum in WAIC 2025, hosted by Prof. [Dahua Lin](https://scholar.google.com/citations?user=GMzzRRUAAAAJ&hl=en), 2025.
- Invited to give a talk at [Shanghai Artificial Intelligence Laboratory](https://www.shlab.org.cn/), 2025.
- Invited to give a talk at [Princeton AI Lab](https://ai.princeton.edu/ai-lab), hosted by Prof. [Mengdi Wang](https://ece.princeton.edu/people/mengdi-wang), 2024.

# Honors & Awards
### Academic Recognition
- **2025 WAIC Yunfan Award Finalist**, 2025
- **Outstanding Graduate**, Peking University Ph.D., 2025
- **KAUST Rising Stars in AI Symposium** (24 selected worldwide), 2025
- **WAIC AI Elite Forum** (20 selected worldwide), 2024
- **VALSE Distinguished Student Forum** (8 selected in China), 2024
- **Baidu Scholarship Nominee** (20 selected worldwide), 2023

### University Honors
- **National Scholarship** for Ph.D. students (Top 1% at PKU), 2022
- **Exceptional Award for Academic Innovation** (Top 1% at PKU), 2022
- **First-class Academic Scholarship**, 2018-2020

### Industry Recognition
- **TechBeat Influencers List** (20 selected in China), 2023 & 2024
- **Outstanding Author**, Electronics Industry Press, 2023

<!--
* Completed my Ph.D. degree as an **Outstanding Graduate** in Peking University.
* Selected as the [KAUST Rising Stars in AI Symposium](https://www.kaust.edu.sa/en/news/rising-stars-in-ai-symposium-2025#:~:text=Following%20the%20resounding%20success%20of,for%20April%207-10th%202025.) (**24 people in the world**), 2025.
* Selected for AI Elite Forum of [WAIC](https://business.cctv.com/special/2024WAIC/index.shtml) (**20 people in the world**), 2024.
* Selected for the distinguished student forum of [VALSE](https://valser.org/2024/#/program) (**8 People in China**), 2024.
* Selected for [Annual Outstanding Author of Electronics Industry Press](https://www.phei.com.cn/), 2023.
* Selected for two consecutive years in the TechBeat Influencers List ([2023 list](https://mp.weixin.qq.com/s/k-HKTjijLP2uVrf7YEfXbA) and [2024 list](https://mp.weixin.qq.com/s/4KT0fAdx1hok0cEU5XcNIQ), **20 people in China**).
* [Baidu Scholarship Nominee](http://scholarship.baidu.com/) (**20 people in the world**), 2023.
* National Scholarship for Ph.D student (**Top 1% in PKU**), 2022.
* Exceptional Award for Academic Innovation for Ph.D student (**Top 1% in PKU**), 2022.
* First-class Academic Scholarship, 2018, 2019, 2020.
-->

<!--
<script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=a&t=tt&d=FiS2xt_QkmMdwTwjXby8DIRX68-V52TTP4RIMV8iblM&co=2d78ad&cmo=3acc3a&cmn=ff5353&ct=ffffff'></script>
-->
