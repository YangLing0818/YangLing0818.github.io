---
permalink: /
title: "Biography"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am currently a Postdoctoral Scholar in the [Department of ECE at Princeton University](https://ece.princeton.edu/), co-affiliated with [Princeton AI Lab](https://ai.princeton.edu/ai-lab), fortunately working with Prof. [Mengdi Wang](https://mwang.princeton.edu/). Prior to this, I served as a Senior Research Assistant at Princeton University from January to July 2025. I received my Ph.D. degree from Peking University in July 2025, jointly supervised by Prof. [Bin Cui](https://cuibinpku.github.io/) and Prof. [Luxia Zhang](https://www.nihds.pku.edu.cn/en/info/1027/1002.htm). During my doctoral studies, I was selected for the [ByteDance Top Seed Talent Program](https://seed.bytedance.com/en/topseed?view_from=homepage_tab). I was also fortunate to collaborate with [Yang Song](https://yang-song.net/), [Shuicheng Yan](https://scholar.google.com.hk/citations?user=DNuiPHwAAAAJ&hl=zh-CN), [Ming-Hsuan Yang](https://scholar.google.com/citations?user=p9-ohHsAAAAJ&hl=zh-CN), [Bernard Ghanem](https://scholar.google.com/citations?user=rVsGTeEAAAAJ&hl=zh-CN), [Jiajun Wu](https://scholar.google.com/citations?user=2efgcS0AAAAJ&hl=zh-CN), [Stefano Ermon](https://scholar.google.com/citations?user=ogXTOZ4AAAAJ&hl=en), [Jure Leskovec](https://scholar.google.com/citations?user=Q_kKkIUAAAAJ&hl=zh-CN), [Yejin Choi](https://scholar.google.com/citations?user=vhP-tlcAAAAJ&hl=zh-CN), and [James Zou](https://scholar.google.com.hk/citations?user=23ZXZvEAAAAJ&hl=zh-CN).

I currently focus on developing advanced generative models, including their *training methodologies, architecture design, alignment, inference efficiency and applications*. I am in charge of [a reasearch team](https://github.com/Gen-Verse) at Princeton and have led a series of works on LLMs/MLLMs and Diffusion Models, including [RPG-DiffusionMaster](https://openreview.net/forum?id=DgLFkAPwuZ) ![GitHub stars](https://img.shields.io/github/stars/YangLing0818/RPG-DiffusionMaster)

<div style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); padding: 20px; border-radius: 12px; margin: 20px 0; color: white;">
<p style="margin: 0; font-size: 1.05em;">
<strong>üéØ We are looking for self-motivated students and insightful collaborators</strong> for research in <em>LLM/MLLM Post-Training, Diffusion LLMs, World Modeling, Agent Training</em>. Please feel free to reach out for potential collaborations or discussions. When contacting, please include a brief self-introduction or attach your CV for meaningful exchange.
</p>
</div>

<p align="center">
<a href="mailto:yangling0818@163.com">üìß Email</a> ÔΩú
<a href="/_pages/image-1.png">üí¨ WeChat</a> ÔΩú
<a href="https://github.com/YangLing0818">üîó Github</a> ÔΩú
<a href="https://github.com/Gen-Verse">üë• Group Github</a> ÔΩú
<a href="https://scholar.google.com.hk/citations?user=sIKujqAAAAAJ&hl=en">üìö Google Scholar</a> ÔΩú
<a href="https://x.com/LingYang_PU">ùïè Twitter</a> ÔΩú
<a href="https://huggingface.co/Gen-Verse">ü§ó HuggingFace</a> ÔΩú
<a href="https://www.xiaohongshu.com/user/profile/5bf9033627150f0001533e35">üìï Â∞èÁ∫¢‰π¶</a>
</p>

---

# Research Summary

My goal is to build powerful generative models or AI systems capable of **understanding, generating, reasoning, interacting and optimizing** across diverse modalities and scenarios.

<p align="center">
<img src="https://github.com/user-attachments/assets/db32d04f-4ac7-4fd9-b100-da9c999e3e2b" alt="Research Overview" style="max-width: 100%; border-radius: 8px; box-shadow: 0 4px 12px rgba(0,0,0,0.15);"/>
</p>

<table style="width: 100%; border-collapse: separate; border-spacing: 0 12px;">
<tr>
<td style="background: #f8f9fa; padding: 16px; border-radius: 8px; vertical-align: top; width: 50%;">
<h4 style="margin-top: 0; color: #2c3e50;">üß† Generative Model Foundations</h4>
<p><strong>Diffusion Model Foundations:</strong> <a href="https://openreview.net/forum?id=DgLFkAPwuZ">RPG</a>, <a href="https://github.com/Gen-Verse/MMaDA">MMaDA</a>, <a href="https://openreview.net/forum?id=nFMS6wF2xq">ContextDiff</a>, <a href="https://arxiv.org/abs/2509.06949">dLLM-RL</a>, <a href="https://arxiv.org/abs/2407.02398">Consistency Flow Matching</a>, <a href="https://arxiv.org/abs/2502.12146">Diffusion-Sharpening</a>, <a href="https://openreview.net/forum?id=nEDToD1R8M">Rectified Diffusion</a>, <a href="https://proceedings.neurips.cc/paper_files/paper/2023/hash/7664a7e946a84ac5e97649a967717cf2-Abstract-Conference.html">ConPreDiff</a>, <a href="https://openaccess.thecvf.com/content/CVPR2024/html/Yang_Structure-Guided_Adversarial_Training_of_Diffusion_Models_CVPR_2024_paper.html">SADM</a>, <a href="https://github.com/tyfeld/MMaDA-Parallel">MMaDA-Parallel</a></p>
<p><strong>Language Model Innovations:</strong> <a href="https://arxiv.org/pdf/2406.04271">Buffer of Thought</a>, <a href="https://github.com/Gen-Verse/MMaDA">MMaDA</a>, <a href="https://github.com/Gen-Verse/ReasonFlux">ReasonFlux</a>, <a href="https://github.com/Gen-Verse/CURE">ReasonFlux-Coder</a>, <a href="https://github.com/Gen-Verse/ReasonFlux">ReasonFlux-PRM</a>, <a href="https://arxiv.org/abs/2509.06949">TraDo</a>, <a href="https://arxiv.org/abs/2410.09008">SuperCorrect</a>, <a href="https://arxiv.org/abs/2511.20639">LatentMAS</a>, <a href="https://arxiv.org/abs/2512.13278">AutoTool</a></p>
<p><strong>Large-Scale Reinforcement Learning:</strong> <a href="https://github.com/Gen-Verse/dLLM-RL">dLLM-RL</a>, <a href="https://github.com/Gen-Verse/MMaDA">MMaDA</a>, <a href="https://github.com/Gen-Verse/CURE">ReasonFlux-Coder</a>, <a href="https://github.com/Gen-Verse/ReasonFlux">ReasonFlux-PRM</a>, <a href="https://arxiv.org/abs/2502.12148">HermesFlow</a>, <a href="https://arxiv.org/abs/2510.11701">Demystifying Agent RL</a></p>
<p><strong>Intelligent Agent Systems:</strong> <a href="https://arxiv.org/abs/2505.20286">Alita</a>, <a href="https://arxiv.org/abs/2506.14728">AgentDistill</a>, <a href="https://github.com/Gen-Verse/ScoreFlow">ScoreFlow</a>, <a href="https://arxiv.org/abs/2410.08102">Multi-Actor Collaboration</a>, <a href="https://arxiv.org/abs/2508.09632">Preacher</a>, <a href="https://arxiv.org/abs/2504.09689">EmoAgent</a>, <a href="https://arxiv.org/abs/2510.11701">DemyAgent</a>, <a href="https://arxiv.org/abs/2511.20639">LatentMAS</a>, <a href="https://github.com/Gen-Verse/GenEnv">GenEnv</a></p>
</td>
<td style="width: 12px;"></td>
<td style="background: #f8f9fa; padding: 16px; border-radius: 8px; vertical-align: top; width: 50%;">
<h4 style="margin-top: 0; color: #2c3e50;">üé® Generative Applications</h4>
<p><strong>Multimodal Content Generation</strong> (spanning image, 3D, and 4D synthesis): <a href="https://openreview.net/forum?id=4w99NAikOE">IterComp</a>, <a href="https://arxiv.org/abs/2406.04277">VideoTetris</a>, <a href="https://github.com/happyw1nd/ScoreLiDAR">ScoreLiDAR</a>, <a href="https://openreview.net/forum?id=3PguviI7Uf">IPDreamer</a>, <a href="https://arxiv.org/abs/2405.14785">EditWorld</a>, <a href="https://arxiv.org/abs/2410.07155">Trans4D</a>, <a href="https://arxiv.org/abs/2503.13435">WideRange4D</a>, <a href="https://arxiv.org/abs/2510.13804">OmniVerifier</a>, <a href="https://github.com/tyfeld/MMaDA-Parallel">MMaDA-Parallel</a>, <a href="https://github.com/thu-ml/DiT-Extrapolation">UltraViCo</a></p>
<p><strong>AI for Scientific Discovery:</strong> <a href="https://openreview.net/forum?id=qH9nrMNTIW">IPDiff</a>, <a href="https://openreview.net/forum?id=eejhD9FCP3">IRDiff</a>, <a href="https://ojs.aaai.org/index.php/AAAI/article/view/29162">BindDM</a>, <a href="https://arxiv.org/abs/2505.19501">RL for Scientific Reasoning</a></p>
<hr style="margin: 20px 0; border: none; border-top: 1px dashed #ccc;">
<h4 style="margin-top: 0; color: #2c3e50;">üìñ Book Publication</h4>
<p><strong>"Diffusion Model: Theory, Application, and Code Practice of Generative AI Models"</strong><br>
Published by Electronics Industry Press (ÁîµÂ≠êÂ∑•‰∏öÂá∫ÁâàÁ§æ), 2023<br>
<a href="https://item.m.jd.com/product/14075554.html">üìó Purchase Link</a> ÔΩú Selected as <strong>Annual Outstanding Author</strong></p>
</td>
</tr>
</table>

---

# What's New

<div style="max-height: 400px; overflow-y: auto; padding: 16px; background: #fafbfc; border-radius: 8px; border-left: 4px solid #667eea;">

üÜï We release a series of works, such as [MMaDA-Parallel](https://github.com/tyfeld/MMaDA-Parallel), [LatentMAS](https://arxiv.org/abs/2511.20639), [GenEnv](https://github.com/Gen-Verse/GenEnv) and [UltraViCo](https://github.com/thu-ml/DiT-Extrapolation).

üèÜ Our [AutoTool](https://arxiv.org/abs/2512.13278) won **Best Paper Award** in [ICCV 2025 Workshop on Multi-Modal Reasoning for Agentic Intelligence](https://agent-intelligence.github.io/agent-intelligence/).

üé§ Invited to give a talk at [ICCV 2025 Workshop on Multi-Modal Reasoning for Agentic Intelligence](https://agent-intelligence.github.io/agent-intelligence/).

üìÑ **5 papers** about LLMs and Multimodal LLMs are accepted by **NeurIPS 2025**, including [MMaDA](https://github.com/Gen-Verse/MMaDA), [CURE & ReasonFlux-Coder](https://github.com/Gen-Verse/ReasonFlux) **(Spotlight Paper, Top 3%)**, [ReasonFlux-PRM](https://github.com/Gen-Verse/ReasonFlux), [Transformer-Copilot](https://arxiv.org/abs/2505.16270) **(Spotlight Paper, Top 3%)** and [HermesFlow](https://arxiv.org/abs/2502.12148).

üìÑ **3 papers** about LLMs and Agents are accepted by **EMNLP 2025**, including [EmoAgent](https://arxiv.org/abs/2504.09689) **(Oral Paper, Top 1%)** and [TreeBoN](https://arxiv.org/abs/2410.16033).

üìÑ **2 papers** about diffusion are accepted by **ACM MM 2025**, including [Inversion-DPO](https://arxiv.org/abs/2507.11554) and [EditWorld](https://arxiv.org/abs/2405.14785).

üèÖ I was selected as a finalist for the [2025 WAIC Yunfan Award](https://www.thegaiaa.org/en/awards_mrzx).

üé§ I was invited to participate in a roundtable forum at WAIC 2025, hosted by Prof. [Dahua Lin](https://scholar.google.com/citations?user=GMzzRRUAAAAJ&hl=en).

üìÑ **2 papers** about agent and diffusion are accepted by **ICCV 2025**, including one [ScoreLiDAR](https://github.com/happyw1nd/ScoreLiDAR)**(Oral Paper)** **(Oral Paper, Top 1%)** and [Paper2Video Agent](https://arxiv.org/abs/2508.09632).

üìÑ **1 paper** about LLMs is accepted by **ACL 2025**, including [Multi-Actor Collaboration](https://arxiv.org/abs/2410.08102).

‚≠ê I was invited as an **Area Chair** at **NeurIPS 2025**.

üìÑ **6 papers** about LLMs and Diffusion Models are accepted by **ICLR 2025**, including [SuperCorrect](https://arxiv.org/abs/2410.09008), [Rectified Diffusion](https://openreview.net/forum?id=nEDToD1R8M), [IterComp](https://openreview.net/forum?id=4w99NAikOE) and [IPDreamer](https://openreview.net/forum?id=3PguviI7Uf).

üé§ I was invited to give a talk at Princeton AI Lab, hosted by Prof. [Mengdi Wang](https://ece.princeton.edu/people/mengdi-wang).

üìÑ **5 papers** about Diffusion Models and LLMs are accepted by **NeurIPS 2024**, including [Buffer of Thoughts](https://github.com/YangLing0818/buffer-of-thought-llm) **(Spotlight Paper, Top 3%)**.

üìÑ **2 papers** about Diffusion Models and AI for Science are accepted by **ICML 2024**.

üìÑ **1 paper** about general/molecular graph diffusion is accepted by **TKDE 2024**.

üìÑ **1 paper** about improved training algorithm of Diffusion Transformers (DiT), DDPMs and Score SDEs is accepted by **CVPR 2024**.

üìÑ **3 papers** about Diffusion Models, GNN, AI for Science are accepted by **ICLR 2024**.

üìÑ **1 paper** about molecular diffusion models is accepted by **AAAI 2024**.

üìÑ **1 paper** about diffusion model survey collaborating with OpenAI is accepted by **ACM Computing Surveys**.

üìÑ **1 paper** about diffusion models is accepted by **NeurIPS 2023**.

üìñ I publish [a book about Diffusion Models](https://item.m.jd.com/product/14075554.html).

üìÑ **1 paper** is accepted by **TNNLS 2023**.

üìÑ **1 paper** is accepted by **TKDE 2023**.

üìÑ **2 papers** are accepted as **ICML 2022** **(Spotlight Paper, Top 3%)**.

üìÑ **1 paper** is accepted by **CVPR 2020**.

</div>

---

# Selected Publications

<p style="color: #666; font-style: italic;">*Co-first author, +Corresponding author ¬∑ For a complete list, see my <a href="https://scholar.google.com.hk/citations?user=sIKujqAAAAAJ&hl=en">Google Scholar profile</a></p>

## Recent Highlighted Work

<div style="background: linear-gradient(to right, #f8f9fa, #ffffff); padding: 20px; border-radius: 10px; margin: 16px 0; border-left: 4px solid #667eea;">

**Latent Collaboration in Multi-Agent Systems**  
Jiaru Zou, Xiyuan Yang, Ruizhong Qiu, Gaotang Li, Katherine Tieu, Pan Lu, Ke Shen, Hanghang Tong, Yejin Choi, Jingrui He, James Zou, Mengdi Wang, **Ling Yang**+  
[paper](https://arxiv.org/abs/2511.20639) ÔΩú [code](https://github.com/Gen-Verse/LatentMAS) ÔΩú [tweet](https://x.com/stanfordnlp/status/1996354695913492889?s=20)

</div>

<div style="background: linear-gradient(to right, #fff9e6, #ffffff); padding: 20px; border-radius: 10px; margin: 16px 0; border-left: 4px solid #f0ad4e;">

**Buffer of Thoughts: Thought-Augmented Reasoning with Large Language Models**  
**Ling Yang**+, Zhaochen Yu, Tianjun Zhang, Shiyi Cao, Minkai Xu, Wentao Zhang, Joseph E Gonzalez, Bin Cui  
NeurIPS 2024 <span style="background: #f0ad4e; color: white; padding: 2px 8px; border-radius: 4px; font-size: 0.85em;">Spotlight Top 3%</span>  
[paper](https://arxiv.org/pdf/2406.04271) ÔΩú [code](https://github.com/YangLing0818/buffer-of-thought-llm) ÔΩú [tweet](https://x.com/omarsar0/status/1799113545696567416)

</div>

<div style="background: #f8f9fa; padding: 20px; border-radius: 10px; margin: 16px 0;">

**Mastering Text-to-Image Diffusion: Recaptioning, Planning, and Generating with Multimodal LLMs**  
**Ling Yang**+, Zhaochen Yu, Chenlin Meng, Minkai Xu, Stefano Ermon, Bin Cui  
ICML 2024  
[paper](https://openreview.net/forum?id=DgLFkAPwuZ) ÔΩú [code](https://github.com/YangLing0818/RPG-DiffusionMaster) ÔΩú [tweet](https://x.com/_akhaliq/status/1749633221514461489)

</div>

<div style="background: #f8f9fa; padding: 20px; border-radius: 10px; margin: 16px 0;">

**MMaDA: Multimodal Large Diffusion Language Models**  
**Ling Yang**+, Ye Tian, Bowen Li, Xinchen Zhang, Ke Shen, Yunhai Tong, Mengdi Wang  
NeurIPS 2025  
[paper](https://arxiv.org/abs/2505.15809) ÔΩú [code](https://github.com/Gen-Verse/MMaDA) ÔΩú [tweet](https://x.com/_akhaliq/status/1925384556279898139)

</div>

<div style="background: #f8f9fa; padding: 20px; border-radius: 10px; margin: 16px 0;">

**Revolutionizing Reinforcement Learning Framework for Diffusion Large Language Models**  
Yinjie Wang, **Ling Yang**\*+, Bowen Li, Ye Tian, Ke Shen, Mengdi Wang  
[paper](https://arxiv.org/abs/2509.06949) ÔΩú [code](https://github.com/Gen-Verse/dLLM-RL) ÔΩú [tweet](https://x.com/_akhaliq/status/1965422743194927429)

</div>

<div style="background: #f8f9fa; padding: 20px; border-radius: 10px; margin: 16px 0;">

**ReasonFlux: Hierarchical LLM Reasoning via Scaling Thought Templates**  
**Ling Yang**+, Zhaochen Yu, Bin Cui, Mengdi Wang  
[paper](https://arxiv.org/abs/2502.06772) ÔΩú [code](https://github.com/Gen-Verse/ReasonFlux) ÔΩú [tweet](https://x.com/_akhaliq/status/1889187356651012599)

</div>

<div style="background: linear-gradient(to right, #fff9e6, #ffffff); padding: 20px; border-radius: 10px; margin: 16px 0; border-left: 4px solid #f0ad4e;">

**Co-Evolving LLM Coder and Unit Tester via Reinforcement Learning (ReasonFlux-Coder)**  
Yinjie Wang, **Ling Yang**\*+, Ye Tian, Ke Shen, Mengdi Wang  
NeurIPS 2025 <span style="background: #f0ad4e; color: white; padding: 2px 8px; border-radius: 4px; font-size: 0.85em;">Spotlight Top 3%</span>  
[paper](https://arxiv.org/abs/2506.03136) ÔΩú [code](https://github.com/Gen-Verse/CURE) ÔΩú [tweet](https://x.com/_akhaliq/status/1930281721926234437)

</div>

<div style="background: #f8f9fa; padding: 20px; border-radius: 10px; margin: 16px 0;">

**ReasonFlux-PRM: Trajectory-Aware PRMs for Long Chain-of-Thought Reasoning in LLMs**  
Jiaru Zou, **Ling Yang**\*+, Jingwen Gu, Jiahao Qiu, Ke Shen, Jingrui He, Mengdi Wang  
NeurIPS 2025  
[paper](https://arxiv.org/abs/2506.18896) ÔΩú [code](https://github.com/Gen-Verse/ReasonFlux) ÔΩú [tweet](https://x.com/_akhaliq/status/1937345023005048925)

</div>

<div style="background: #f8f9fa; padding: 20px; border-radius: 10px; margin: 16px 0;">

**SuperCorrect: Advancing Small LLM Reasoning with Thought Template Distillation and Self-Correction**  
**Ling Yang**+, Zhaochen Yu, Tianjun Zhang, Minkai Xu, Joseph E. Gonzalez, Bin CUI, Shuicheng YAN  
ICLR 2025  
[paper](https://openreview.net/forum?id=PyjZO7oSw2) ÔΩú [code](https://github.com/YangLing0818/SuperCorrect-llm)

</div>

<div style="background: linear-gradient(to right, #fff9e6, #ffffff); padding: 20px; border-radius: 10px; margin: 16px 0; border-left: 4px solid #f0ad4e;">

**Transformer Copilot: Learning from The Mistake Log in LLM Fine-tuning**  
Jiaru Zou, Yikun Ban, Zihao Li, Yunzhe Qi, Ruizhong Qiu, **Ling Yang**+, Jingrui He  
NeurIPS 2025 <span style="background: #f0ad4e; color: white; padding: 2px 8px; border-radius: 4px; font-size: 0.85em;">Spotlight Top 3%</span>  
[paper](https://arxiv.org/abs/2505.16270) ÔΩú [code](https://github.com/jiaruzouu/TransformerCopilot)

</div>

<div style="background: linear-gradient(to right, #e8f5e9, #ffffff); padding: 20px; border-radius: 10px; margin: 16px 0; border-left: 4px solid #4caf50;">

**Distilling Diffusion Models to Efficient 3D LiDAR Scene Completion**  
Shengyuan Zhang, An Zhao, **Ling Yang**, Zejian Li, Chenye Meng, Haoran Xu, Tianrun Chen, AnYang Wei, Perry Pengyun GU, Lingyun Sun  
ICCV 2025 <span style="background: #4caf50; color: white; padding: 2px 8px; border-radius: 4px; font-size: 0.85em;">Oral Top 1%</span>  
[paper](https://arxiv.org/abs/2412.03515) ÔΩú [code](https://github.com/happyw1nd/ScoreLiDAR)

</div>

---

## Core Contributions to Generative Foundations and Applications

<details>
<summary style="cursor: pointer; font-weight: bold; padding: 10px; background: #f0f0f0; border-radius: 6px;">üìö Click to expand full list</summary>

<div style="padding: 16px;">

- **HermesFlow: Seamlessly Closing the Gap in Multimodal Understanding and Generation**  
  Ling Yang+, Xinchen Zhang, Ye Tian, Chenming Shang, Minghao Xu, Wentao Zhang, Bin Cui  
  NeurIPS 2025 ¬∑ [paper](https://arxiv.org/abs/2502.12148) ÔΩú [code](https://github.com/Gen-Verse/HermesFlow)

- **IterComp: Iterative Composition-Aware Feedback Learning from Model Gallery for Text-to-Image Generation**  
  Xinchen Zhang\*, **Ling Yang**\*, Guohao Li, Yaqi Cai, Jiake Xie, Yong Tang, Yujiu Yang, Mengdi Wang, Bin Cui  
  ICLR 2025 ¬∑ [paper](https://arxiv.org/abs/2410.07171) ÔΩú [code](https://github.com/YangLing0818/IterComp) ÔΩú [tweet](https://x.com/_akhaliq/status/1844272544687509910)

- **Rectified Diffusion: Straightness Is Not Your Need in Rectified Flow**  
  Fu-Yun Wang, **Ling Yang**, Zhaoyang Huang, Mengdi Wang, Hongsheng Li  
  ICLR 2025 ¬∑ [paper](https://openreview.net/forum?id=nEDToD1R8M) ÔΩú [code](https://github.com/G-U-N/Rectified-Diffusion)

- **Consistency Flow Matching: Defining Straight Flows with Velocity Consistency**  
  **Ling Yang**+, Zixiang Zhang, Zhilong Zhang, Xingchao Liu, Minkai Xu, Wentao Zhang, Chenlin Meng, Stefano Ermon, Bin Cui  
  [paper](https://arxiv.org/abs/2407.02398) ÔΩú [code](https://github.com/YangLing0818/consistency_flow_matching) ÔΩú [tweet](https://x.com/LingYang_PKU/status/1808509588414800224)

- **Cross-Modal Contextualized Diffusion Models for Text-Guided Visual Generation and Editing**  
  **Ling Yang**, Zhilong Zhang, Zhaochen Yu, Jingwei Liu, Minkai Xu, Stefano Ermon, Bin CUI  
  ICLR 2024 ¬∑ [paper](https://openreview.net/forum?id=nFMS6wF2xq) ÔΩú [code](https://github.com/YangLing0818/ContextDiff)

- **Structure-Guided Adversarial Training of Diffusion Models**  
  **Ling Yang**, Haotian Qian, Zhilong Zhang, Jingwei Liu, Bin CUI  
  CVPR 2024 ¬∑ [paper](https://openaccess.thecvf.com/content/CVPR2024/papers/Yang_Structure-Guided_Adversarial_Training_of_Diffusion_Models_CVPR_2024_paper.pdf)

- **Improving Diffusion-Based Image Synthesis with Context Prediction**  
  **Ling Yang**, Jingwei Liu, Shenda Hong, Zhilong Zhang, Zhilin Huang, Zheming Cai, Wentao Zhang, Bin CUI  
  NeurIPS 2024 ¬∑ [paper](https://proceedings.neurips.cc/paper_files/paper/2023/hash/7664a7e946a84ac5e97649a967717cf2-Abstract-Conference.html)

- **Diffusion Models: A Comprehensive Survey of Methods and Applications**  
  **Ling Yang**, Zhilong Zhang, **Yang Song (OpenAI)**, Shenda Hong, Runsheng Xu, Yue Zhao, Wentao Zhang, Bin CUI, Ming-Hsuan Yang  
  ACM Computing Surveys 2023 ¬∑ [paper](https://arxiv.org/abs/2209.00796) ÔΩú [code](https://github.com/YangLing0818/Diffusion-Models-Papers-Survey-Taxonomy)

- **VideoTetris: Towards Compositional Text-to-Video Generation**  
  Ye Tian\*, **Ling Yang**\*+, Haotian Yang, Yuan Gao, Yufan Deng, Jingmin Chen, Xintao Wang, Zhaochen Yu, Xin Tao, Pengfei Wan, Di Zhang, Bin Cui  
  NeurIPS 2024 ¬∑ [paper](https://arxiv.org/abs/2406.04277) ÔΩú [code](https://github.com/YangLing0818/VideoTetris) ÔΩú [tweet](https://x.com/_akhaliq/status/1798897351534489608)

</div>
</details>

---

## Additional Selected Publications

<details>
<summary style="cursor: pointer; font-weight: bold; padding: 10px; background: #f0f0f0; border-radius: 6px;">üìö Click to expand full list</summary>

<div style="padding: 16px;">

- **VQGraph: Rethinking Graph Representation Space for Bridging GNNs and MLPs**  
  **Ling Yang**, Ye Tian, Minkai Xu, Zhongyi Liu, Shenda Hong, Wei Qu, Wentao Zhang, Bin Cui, Muhan Zhang, Jure Leskovec  
  ICLR 2024 ¬∑ [paper](https://openreview.net/forum?id=h6Tz85BqRI) ÔΩú [code](https://github.com/YangLing0818/VQGraph)

- **Dpgn: Distribution propagation graph network for few-shot learning**  
  **Ling Yang**, Liangliang Li, Zilun Zhang, Xinyu Zhou, Erjin Zhou, Yu Liu  
  CVPR 2020 ¬∑ [paper](http://openaccess.thecvf.com/content_CVPR_2020/html/Yang_DPGN_Distribution_Propagation_Graph_Network_for_Few-Shot_Learning_CVPR_2020_paper.html) ÔΩú [code](https://github.com/megvii-research/DPGN)

- **Unsupervised time-series representation learning with iterative bilinear temporal-spectral fusion**  
  **Ling Yang**+, Shenda Hong  
  ICML 2022 **(Spotlight Top 3%)** ¬∑ [paper](https://proceedings.mlr.press/v162/yang22e.html)

- **EmoAgent: Assessing and Safeguarding Human-AI Interaction for Mental Health Safety**  
  Jiahao Qiu, Yinghui He, Xinzhe Juan, Yimin Wang, Yuhan Liu, Zixin Yao, Yue Wu, Xun Jiang, Ling Yang, Mengdi Wang  
  EMNLP 2025 **(Oral Top 1%)** ¬∑ [paper](https://arxiv.org/abs/2504.09689) ÔΩú [code](https://github.com/1akaman/EmoAgent)

</div>
</details>

---

# Academic Services

<table style="width: 100%;">
<tr>
<td style="vertical-align: top; padding: 12px; width: 50%;">
<h4>‚≠ê Area Chair</h4>
<ul>
<li>NeurIPS, ICLR</li>
</ul>
</td>
<td style="vertical-align: top; padding: 12px; width: 50%;">
<h4>üìù Journal Reviewer</h4>
<ul>
<li>ACM Computing Surveys (CSUR)</li>
<li>IEEE TPAMI, TKDE, TCSVT, TNNLS</li>
<li>Pattern Recognition (PR)</li>
</ul>
</td>
</tr>
</table>

**Program Committee or Reviewer:**
- ICML 2025, ICLR 2025, CVPR 2025, ICCV 2025, AAAI 2025
- SIGGRAPH 2024, ICML 2024, ICLR 2024, NeurIPS 2024, CVPR 2024, AAAI 2024
- ICML 2023, ICLR 2023, NeurIPS 2023, CVPR 2023, AAAI 2023
- ICML 2022, ICLR 2022, NeurIPS 2022

---

# Invited Talks

| Year | Event |
|------|-------|
| 2025 | ICCV 2025 Workshop on [MMRAgI](https://agent-intelligence.github.io/agent-intelligence/) |
| 2025 | [Institute of Automation of the Chinese Academy of Sciences](http://english.ia.cas.cn/) |
| 2025 | Roundtable forum in WAIC 2025, hosted by Prof. [Dahua Lin](https://scholar.google.com/citations?user=GMzzRRUAAAAJ&hl=en) |
| 2025 | [Shanghai Artificial Intelligence Laboratory](https://www.shlab.org.cn/) |
| 2024 | [Princeton AI Lab](https://ai.princeton.edu/ai-lab), hosted by Prof. [Mengdi Wang](https://ece.princeton.edu/people/mengdi-wang) |

---

# Honors & Awards

<div style="display: flex; flex-wrap: wrap; gap: 12px;">

<span style="background: linear-gradient(135deg, #667eea, #764ba2); color: white; padding: 8px 16px; border-radius: 20px; font-size: 0.9em;">üèÜ 2025 WAIC Yunfan Award Finalist</span>

<span style="background: linear-gradient(135deg, #f093fb, #f5576c); color: white; padding: 8px 16px; border-radius: 20px; font-size: 0.9em;">üéì Outstanding Graduate, PKU Ph.D. 2025</span>

<span style="background: linear-gradient(135deg, #4facfe, #00f2fe); color: white; padding: 8px 16px; border-radius: 20px; font-size: 0.9em;">üåü KAUST Rising Stars in AI (24 worldwide)</span>

<span style="background: linear-gradient(135deg, #43e97b, #38f9d7); color: white; padding: 8px 16px; border-radius: 20px; font-size: 0.9em;">üí¨ VALSE Distinguished Student Forum (8 in China)</span>

<span style="background: linear-gradient(135deg, #fa709a, #fee140); color: white; padding: 8px 16px; border-radius: 20px; font-size: 0.9em;">üìñ Outstanding Author, Electronics Industry Press 2023</span>

<span style="background: linear-gradient(135deg, #a18cd1, #fbc2eb); color: white; padding: 8px 16px; border-radius: 20px; font-size: 0.9em;">üèÖ National Scholarship (Top 1% PKU) 2022</span>

<span style="background: linear-gradient(135deg, #ffecd2, #fcb69f); color: #333; padding: 8px 16px; border-radius: 20px; font-size: 0.9em;">‚≠ê Exceptional Award for Academic Innovation 2022</span>

</div>
